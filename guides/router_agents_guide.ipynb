{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI & Machine Learning (KAN-CINTO4003U) - Copenhagen Business School | Spring 2025**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"media/agents_header.png\" alt=\"LLM\" width=\"800\"/> <br>\n",
    "Image from TrueFoundry's \"<i><a href=\"https://www.truefoundry.com/blog/llm-agents\">What are LLM Agents?</a></i>\". <br>Copyright © 2025. All rights reserved.\n",
    "</p>\n",
    "\n",
    "***\n",
    "Sources: <br>\n",
    "- [What are LLM Agents? (TrueFoundry)](https://www.truefoundry.com/blog/llm-agents)\n",
    "- [What is an AI Agent? (LangChain)](https://blog.langchain.dev/what-is-an-agent/)\n",
    "\n",
    "\n",
    "# LLM agents\n",
    "\n",
    "Think about how we have used LLMs so far: We have given an LLM a single task. It's easy to consider that we could *chain* these tasks together to create a more complex system. For example, we could ask a language model to generate a summary of a text, and then - in a separate step - ask it to classify the sentiment of the summary. This is what we call *chaining* of LLM tasks. In chains, a sequence of actions is hardcoded (in code). In agents, a language model is used as a *reasoning engine* to determine which actions to take and in which order. In other words, an AI agent is a system that uses an LLM to decide the control flow of an application, instead of having it hardcoded. \n",
    "\n",
    "An LLM Agent will\n",
    "\n",
    "1. Receive a sensory input (e.g. a text)\n",
    "2. Decide what to do with it\n",
    "3. Take an action (e.g. generate a summary)\n",
    "\n",
    "Let's think about the implications of this for a moment. If we can get an LLM to consider a task and then decide for itself how best to solve it, we are approaching a very human-like way of thinking.\n",
    "\n",
    "### What does it mean to be agentic?\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"media/levels-of-agentic.png\" alt=\"LLM\" width=\"800\"/> <br>\n",
    "Image from LangChain's \"<i><a href=\"https://blog.langchain.dev/what-is-an-agent/\">What is an AI agent?</a></i>\" by Harrison Chase, CEO of LangChain AI. <br>Copyright © 2025. All rights reserved.\n",
    "</p>\n",
    "\n",
    "According to Harisson Chase, a system is more “agentic” the more an LLM decides how the system can behave.\n",
    "\n",
    "| Level of Agentic Behavior                                                                 | Description                                                                                                                                                     |\n",
    "|------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Router                                                                                   | Using an LLM to route inputs into a particular downstream workflow has some small amount of “agentic” behavior. This would fall into the `Router` category.       |\n",
    "| Between Router and State Machine                                                        | If you use multiple LLMs to do multiple routing steps, this would be somewhere between `Router` and `State Machine`.                                                |\n",
    "| State Machine                                                                            | If one of those steps is determining whether to continue or finish - effectively allowing the system to run in a loop until finished, it would fall into this category. |\n",
    "| Autonomous Agent                                                                         | If the system is building tools, remembering those, and then taking those in future steps, it is incredibly agentic, similar to what the [Voyager paper](https://arxiv.org/abs/2305.16291) implemented. |\n",
    "\n",
    "### Agents as graph-based systems\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"media/graph.png\" alt=\"LLM\" width=\"800\"/> <br>\n",
    "Image from Ionio \"<i><a href=\"https://www.ionio.ai/blog/a-comprehensive-guide-about-langgraph-code-included\">A Comprehensive Guide About Langgraph</a></i>\". <br>by Shivam Danawale and Pranav Patel<br>\n",
    "Copyright © 2025. All rights reserved.\n",
    "</p>\n",
    "\n",
    "Following the image above, we see that the workflow is triggered by an input from a user. Next, we hit the first node, likely an LLM. This LLM provides an output - not back to the user but to the next nodes, routed via *conditional edges*. In other words, the LLM (our the output of the latest LLM node) will determine which route we will take to answer the query - or carry out the associated task. We can repeat this process for downstream nodes. Eventually, we will end in an *END* node - or we might even return to the first node again and start over!\n",
    "\n",
    "***\n",
    "\n",
    "### Agents in LangGraph\n",
    "\n",
    "We will be using *LangGraph* to create a simple `router` agent system in this notebook. [LangGraph](https://langchain-ai.github.io/langgraph/) is a graph-based system that allows us to create complex workflows using LLMs. A couple of key concepts in LangGraph are:\n",
    "\n",
    "| Concept  | Description |\n",
    "|---------------| ------|\n",
    "| **State**     | State is the central concept in LangGraph. It represents all the information that flows through your application. |\n",
    "| **Node**      | A node is a single unit of computation - just like neurons in neural networks. In LangGraph, nodes are Python functions. For example, Nodes can contain LLM calls (Generate text or make decisions), Tool calls (Interact with external systems), Conditional logic (Determine next steps), Human intervention (Get input from users). Some nodes necessary for the whole workflow like `START` and `END` exist from LangGraph directly. |\n",
    "| **Edges**     | Edges connect nodes and define the possible paths through your graph. |\n",
    "| **StateGraph**| The StateGraph is the container that holds your entire agent workflow. |\n",
    "\n",
    "LangChain has released an excellent [introduction to these concepts here](https://huggingface.co/learn/agents-course/unit2/langgraph/building_blocks)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "In this notebook, we will be using *LangGraph* to create a simple `router` agent system. LangGraph is a graph-based system that allows us to create complex workflows using LLMs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-in libraries\n",
    "from typing import Literal, TypedDict,  Any, Optional\n",
    "\n",
    "# langgraph libraries\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.runnables.graph import  MermaidDrawMethod\n",
    "\n",
    "# misc libraries\n",
    "from pydantic import Field\n",
    "from IPython.display import Image\n",
    "from decouple import config\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# local modules\n",
    "from src.llm import LLMCaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading our WatsonX.ai credentials again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_file_path = \"/Users/henrikjacobsen/Desktop/CBS/Semester 2/Artifical Intelligence and Machine Learning/apikey.json\"\n",
    "\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "WX_API_KEY = data.get(\"apikey\")\n",
    "\n",
    "if WX_API_KEY:\n",
    "    print(\"API Key loaded successfully!\")\n",
    "else:\n",
    "    print(\"Error: API Key not found in JSON file.\")\n",
    "\n",
    "WX_PROJECT_ID = \"0a2386df-d12c-40ee-bda2-190a5c6cc1fd\"\n",
    "WX_API_URL = \"https://us-south.ml.cloud.ibm.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call out neat `LLMCaller` class, defined in `src/llm.py::LLMCaller`, to use `litellm` and `instructor` in a single class. Please check out [guides/instructor_guide.ipynb](instructor_guide.ipynb) for more information on how to use this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LLMCaller(\n",
    "    api_key=WX_API_KEY,\n",
    "    project_id=WX_PROJECT_ID,\n",
    "    api_url=WX_API_URL,\n",
    "    model_id=\"watsonx/ibm/granite-3-2-8b-instruct\",\n",
    "    params={\n",
    "        GenParams.TEMPERATURE: 0.7,\n",
    "        GenParams.MAX_NEW_TOKENS: 300,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "ename": "InstructorRetryException",
     "evalue": "litellm.APIConnectionError: API key is required\nTraceback (most recent call last):\n  File \"/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/main.py\", line 2714, in completion\n    response = watsonx_chat_completion.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/llms/watsonx/chat/handler.py\", line 46, in completion\n    headers = watsonx_chat_transformation.validate_environment(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/llms/watsonx/common_utils.py\", line 187, in validate_environment\n    token = _generate_watsonx_token(api_key=api_key, token=token)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/llms/watsonx/common_utils.py\", line 75, in _generate_watsonx_token\n    token = generate_iam_token(api_key)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/llms/watsonx/common_utils.py\", line 43, in generate_iam_token\n    raise ValueError(\"API key is required\")\nValueError: API key is required\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/main.py:2714\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   2713\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m custom_llm_provider == \u001b[33m\"\u001b[39m\u001b[33mwatsonx\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2714\u001b[39m     response = \u001b[43mwatsonx_chat_completion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2715\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2716\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2717\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2718\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2719\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m=\u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   2728\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pass AsyncOpenAI, OpenAI client\u001b[39;49;00m\n\u001b[32m   2730\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwatsonx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m custom_llm_provider == \u001b[33m\"\u001b[39m\u001b[33mwatsonx_text\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/llms/watsonx/chat/handler.py:46\u001b[39m, in \u001b[36mWatsonXChatHandler.completion\u001b[39m\u001b[34m(self, model, messages, api_base, custom_llm_provider, custom_prompt_dict, model_response, print_verbose, encoding, api_key, logging_obj, optional_params, acompletion, litellm_params, headers, logger_fn, timeout, client, custom_endpoint, streaming_decoder, fake_stream)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m## UPDATE HEADERS\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m headers = \u001b[43mwatsonx_chat_transformation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m## UPDATE PAYLOAD (optional params)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/llms/watsonx/common_utils.py:187\u001b[39m, in \u001b[36mIBMWatsonXMixin.validate_environment\u001b[39m\u001b[34m(self, headers, model, messages, optional_params, api_key, api_base)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     token = \u001b[43m_generate_watsonx_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;66;03m# build auth headers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/llms/watsonx/common_utils.py:75\u001b[39m, in \u001b[36m_generate_watsonx_token\u001b[39m\u001b[34m(api_key, token)\u001b[39m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m token\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m token = \u001b[43mgenerate_iam_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m token\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/llms/watsonx/common_utils.py:43\u001b[39m, in \u001b[36mgenerate_iam_token\u001b[39m\u001b[34m(api_key, **params)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAPI key is required\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m headers[\u001b[33m\"\u001b[39m\u001b[33mAccept\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: API key is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAPIConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/instructor/retry.py:168\u001b[39m, in \u001b[36mretry_sync\u001b[39m\u001b[34m(func, response_model, args, kwargs, context, max_retries, strict, mode, hooks)\u001b[39m\n\u001b[32m    167\u001b[39m hooks.emit_completion_arguments(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m response = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m hooks.emit_completion_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/utils.py:1235\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1232\u001b[39m     logging_obj.failure_handler(\n\u001b[32m   1233\u001b[39m         e, traceback_exception, start_time, end_time\n\u001b[32m   1234\u001b[39m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1235\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/utils.py:1113\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1113\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1114\u001b[39m end_time = datetime.datetime.now()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/main.py:3144\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   3142\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3143\u001b[39m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3144\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3145\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3146\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3147\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3150\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2214\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2213\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2190\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2189\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2190\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(\n\u001b[32m   2191\u001b[39m                 message=\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2192\u001b[39m                     \u001b[38;5;28mstr\u001b[39m(original_exception), traceback.format_exc()\n\u001b[32m   2193\u001b[39m                 ),\n\u001b[32m   2194\u001b[39m                 llm_provider=custom_llm_provider,\n\u001b[32m   2195\u001b[39m                 model=model,\n\u001b[32m   2196\u001b[39m                 request=httpx.Request(\n\u001b[32m   2197\u001b[39m                     method=\u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m, url=\u001b[33m\"\u001b[39m\u001b[33mhttps://api.openai.com/v1/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2198\u001b[39m                 ),  \u001b[38;5;66;03m# stub the request\u001b[39;00m\n\u001b[32m   2199\u001b[39m             )\n\u001b[32m   2200\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2201\u001b[39m     \u001b[38;5;66;03m# LOGGING\u001b[39;00m\n",
      "\u001b[31mAPIConnectionError\u001b[39m: litellm.APIConnectionError: API key is required\nTraceback (most recent call last):\n  File \"/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/main.py\", line 2714, in completion\n    response = watsonx_chat_completion.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/llms/watsonx/chat/handler.py\", line 46, in completion\n    headers = watsonx_chat_transformation.validate_environment(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/llms/watsonx/common_utils.py\", line 187, in validate_environment\n    token = _generate_watsonx_token(api_key=api_key, token=token)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/llms/watsonx/common_utils.py\", line 75, in _generate_watsonx_token\n    token = generate_iam_token(api_key)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/llms/watsonx/common_utils.py\", line 43, in generate_iam_token\n    raise ValueError(\"API key is required\")\nValueError: API key is required\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRetryError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/instructor/retry.py:163\u001b[39m, in \u001b[36mretry_sync\u001b[39m\u001b[34m(func, response_model, args, kwargs, context, max_retries, strict, mode, hooks)\u001b[39m\n\u001b[32m    162\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/tenacity/__init__.py:443\u001b[39m, in \u001b[36mBaseRetrying.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/tenacity/__init__.py:376\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/tenacity/__init__.py:419\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc.reraise()\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[31mRetryError\u001b[39m: RetryError[<Future at 0x17c4ba350 state=finished raised APIConnectionError>]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mInstructorRetryException\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWrite a haiku about a fish\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CBS/Semester 2/Artifical Intelligence and Machine Learning/AIML25/Assignment/ma3/src/llm.py:88\u001b[39m, in \u001b[36mLLMCaller.invoke\u001b[39m\u001b[34m(self, prompt, response_model, **kwargs)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, response_model: ResponseType = BaseResponse, **kwargs\n\u001b[32m     76\u001b[39m ) -> ResponseType:\n\u001b[32m     77\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Sends a prompt to the LLM and retrieves a structured response.\u001b[39;00m\n\u001b[32m     78\u001b[39m \n\u001b[32m     79\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     86\u001b[39m \u001b[33;03m        ResponseType: The structured response from the LLM, parsed into the specified response model.\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m                \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     95\u001b[39m \u001b[43m                \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mProvide your answer as an object of \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# notice how we hardcode instructions on the responde model type for the llm\u001b[39;49;00m\n\u001b[32m     97\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# so we don't have to repeat it in the prompt\u001b[39;49;00m\n\u001b[32m     98\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapikey\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/instructor/client.py:180\u001b[39m, in \u001b[36mInstructor.create\u001b[39m\u001b[34m(self, response_model, messages, max_retries, validation_context, context, strict, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    169\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    170\u001b[39m     response_model: \u001b[38;5;28mtype\u001b[39m[T] | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    176\u001b[39m     **kwargs: Any,\n\u001b[32m    177\u001b[39m ) -> T | Any | Awaitable[T] | Awaitable[Any]:\n\u001b[32m    178\u001b[39m     kwargs = \u001b[38;5;28mself\u001b[39m.handle_kwargs(kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/instructor/patch.py:193\u001b[39m, in \u001b[36mpatch.<locals>.new_create_sync\u001b[39m\u001b[34m(response_model, validation_context, context, max_retries, strict, hooks, *args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m response_model, new_kwargs = handle_response_model(\n\u001b[32m    188\u001b[39m     response_model=response_model, mode=mode, **kwargs\n\u001b[32m    189\u001b[39m )  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    191\u001b[39m new_kwargs = handle_templating(new_kwargs, mode=mode, context=context)\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m response = \u001b[43mretry_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/instructor/retry.py:194\u001b[39m, in \u001b[36mretry_sync\u001b[39m\u001b[34m(func, response_model, args, kwargs, context, max_retries, strict, mode, hooks)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    193\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRetry error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InstructorRetryException(\n\u001b[32m    195\u001b[39m         e.last_attempt._exception,\n\u001b[32m    196\u001b[39m         last_completion=response,\n\u001b[32m    197\u001b[39m         n_attempts=attempt.retry_state.attempt_number,\n\u001b[32m    198\u001b[39m         \u001b[38;5;66;03m#! deprecate messages soon\u001b[39;00m\n\u001b[32m    199\u001b[39m         messages=extract_messages(\n\u001b[32m    200\u001b[39m             kwargs\n\u001b[32m    201\u001b[39m         ),  \u001b[38;5;66;03m# Use the optimized function instead of nested lookups\u001b[39;00m\n\u001b[32m    202\u001b[39m         create_kwargs=kwargs,\n\u001b[32m    203\u001b[39m         total_usage=total_usage,\n\u001b[32m    204\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mInstructorRetryException\u001b[39m: litellm.APIConnectionError: API key is required\nTraceback (most recent call last):\n  File \"/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/main.py\", line 2714, in completion\n    response = watsonx_chat_completion.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/llms/watsonx/chat/handler.py\", line 46, in completion\n    headers = watsonx_chat_transformation.validate_environment(\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/llms/watsonx/common_utils.py\", line 187, in validate_environment\n    token = _generate_watsonx_token(api_key=api_key, token=token)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/llms/watsonx/common_utils.py\", line 75, in _generate_watsonx_token\n    token = generate_iam_token(api_key)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/litellm/llms/watsonx/common_utils.py\", line 43, in generate_iam_token\n    raise ValueError(\"API key is required\")\nValueError: API key is required\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(prompt=\"Write a haiku about a fish\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple AI agent\n",
    "\n",
    "We will build a simple `router` AI agent system: A chatbot - Mailbot, who\n",
    "\n",
    "1. Reads incoming emails\n",
    "2. Classifies them into a list of categories\n",
    "3. Decides whether they are spam or not\n",
    "4. If they are not spam, he will draft a suitable response\n",
    "5. If they are spam, he will move the email to the spam folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to define our `State`. To reiterate, this is the central concept in LangGraph and represents all the information that flows through our application.\n",
    "\n",
    "All these attributes will be populated as we run the agent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailState(TypedDict):\n",
    "\n",
    "    email: dict[str, Any]  # The email being processed - Contains subject, sender, body, etc.\n",
    "    email_category: Optional[str]  # Category of the email (e.g., work, personal, etc.\n",
    "    spam_reason: Optional[str]  # Reason for categorizing the email as spam\n",
    "    is_spam: Optional[bool]  # Whether the email is deemed to be spam or not\n",
    "    draft: Optional[str]  # Draft response to the email\n",
    "    verbose : bool = False  # Whether to provide verbose output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define our *nodes* - the python functions that make up the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our LLM\n",
    "def read_email(state: EmailState):\n",
    "    \"\"\"Mailbot reads and logs the incoming email\"\"\"\n",
    "    email = state[\"email\"]  # Extract the email from the state\n",
    "    \n",
    "    if state[\"verbose\"]:\n",
    "        print(f\"Mailbot is processing an email from {email['sender']} with subject: {email['subject']}\")\n",
    "    \n",
    "    # No state changes needed here\n",
    "    return {} # <- if we don't need to update the state, we return an empty dictionary\n",
    "\n",
    "def classify_email(state: EmailState):\n",
    "    \"\"\"Mailbot uses an LLM to determine if the email is spam or legitimate\"\"\"\n",
    "    email = state[\"email\"]  # Extract the email from the state\n",
    "    \n",
    "    # Prepare our prompt for the LLM\n",
    "    prompt = f\"\"\"Analyze this email and determine if it is spam or legitimate.\n",
    "    \n",
    "    Email:\n",
    "    From: {email['sender']}\n",
    "    Subject: {email['subject']}\n",
    "    Body: {email['body']}\n",
    "    \n",
    "    First, determine if this email is spam. If it is spam, explain why.\n",
    "    If it is legitimate, categorize it (inquiry, complaint, thank you, etc.).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create our response model\n",
    "    response_model = model.create_response_model(\n",
    "        \"EmailAnalysis\", \n",
    "        {\n",
    "            \"spam_reason\": (str, Field(description=\"The reasoning behind the decision.\")),\n",
    "            \"is_spam\": (bool, Field(description=\"Whether the email is spam.\")),\n",
    "            \"email_category\": (Literal[\"Transactional\", \"Marketing\", \"Relational\", \"Administrative\", \"Security/alert\", \"Spam\"], Field(description=\"The category of the email.\")) \n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Call the LLMCaller with the prompt and response model\n",
    "    response = model.invoke(prompt, response_model=response_model)\n",
    "\n",
    "    # Extract the response data\n",
    "    is_spam = response.is_spam\n",
    "    spam_reason = response.spam_reason\n",
    "    email_category = response.email_category\n",
    "    \n",
    "    # Return state updates\n",
    "    return {\n",
    "        \"is_spam\": is_spam,\n",
    "        \"spam_reason\": spam_reason,\n",
    "        \"email_category\": email_category,\n",
    "    }\n",
    "\n",
    "def handle_spam(state: EmailState):\n",
    "    \"\"\"Mailbot discards spam email with a note\"\"\"\n",
    "\n",
    "    if state[\"verbose\"]:\n",
    "        print(f\"Mailbot has identified the email as spam. Reason: {state['spam_reason']}\")\n",
    "        print(\"The email has been moved to the spam folder.\")\n",
    "    \n",
    "    # We're done processing this email\n",
    "    return {}\n",
    "\n",
    "def draft_response(state: EmailState):\n",
    "    \"\"\"Mailbot drafts a preliminary response for legitimate emails\"\"\"\n",
    "    email = state[\"email\"]  # Extract the email from the state\n",
    "    category = state[\"email_category\"] or \"general\"  # Default to a general category if not specified\n",
    "    \n",
    "    # Prepare our prompt for the LLM\n",
    "    prompt = f\"\"\"Draft a polite preliminary response to this email.\n",
    "    \n",
    "    Email:\n",
    "    From: {email['sender']}\n",
    "    Subject: {email['subject']}\n",
    "    Body: {email['body']}\n",
    "    \n",
    "    This email has been categorized as: {category}\n",
    "    \n",
    "    Draft a brief, professional response that your employer can review and personalize before sending.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call the LLM - this time without a custom response model\n",
    "    response = model.invoke(prompt) # we can use the default response model here\n",
    "    answer = response.answer  # Extract the response from the LLM\n",
    "\n",
    "    # Return state updates\n",
    "    return {\"draft\": answer}  # add the draft response to the state\n",
    "\n",
    "def notify(state: EmailState):\n",
    "    \"\"\"Mailbot notifies its employer about the email and presents the draft response\"\"\"\n",
    "    email = state[\"email\"]  # Extract the email from the state\n",
    "    \n",
    "    if state[\"verbose\"]:\n",
    "        # some pretty printing to emulate the notification\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Hi boss, you've received an email from {email['sender']}.\")\n",
    "        print(f\"Subject: {email['subject']}\")\n",
    "        print(f\"Category: {state['email_category']}\")\n",
    "        print(\"\\nI've prepared a draft response for your review:\")\n",
    "        print(\"-\"*50)\n",
    "        print(state[\"draft\"])\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # We're done processing this email\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create our *conditional edge* - the logic that decides which path to take based on the output of the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_email(state: EmailState) -> str:\n",
    "    \"\"\"Determine the next step based on spam classification\"\"\"\n",
    "    if state[\"is_spam\"]: # If the email is spam, meaning \"is_spam\" is True\n",
    "        return \"spam\" # Move to the spam handling step\n",
    "    else:\n",
    "        return \"legitimate\"  # Move to the legitimate email handling step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our `State` and our `nodes`, we need our edges - the connections between the nodes that define the possible paths through our graph.\n",
    "\n",
    "First, we can create our `StateGraph` - the container that holds our entire agent workflow. Then we add nodes and edges to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x17d279690>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the graph\n",
    "email_graph = StateGraph(EmailState)  # Initialize the graph with the EmailState state\n",
    "\n",
    "# Add nodes\n",
    "email_graph.add_node(\"read_email\", read_email)  # Add the read_email node\n",
    "email_graph.add_node(\"classify_email\", classify_email)  # Add the classify_email node\n",
    "email_graph.add_node(\"handle_spam\", handle_spam)  # Add the handle_spam node\n",
    "email_graph.add_node(\"draft_response\", draft_response)  # Add the draft_response node\n",
    "email_graph.add_node(\"notify\", notify)  # Add the notify node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Start the edges - LangGraph requires a start node\n",
    "email_graph.add_edge(START, \"read_email\")  # Start with reading the email\n",
    "# Add edges - defining the flow\n",
    "email_graph.add_edge(\"read_email\", \"classify_email\")  # After reading, classify the email\n",
    "\n",
    "# Add conditional branching from classify_email\n",
    "email_graph.add_conditional_edges(\n",
    "    \"classify_email\",\n",
    "    route_email, # based on this function..\n",
    "    {\n",
    "        \"spam\": \"handle_spam\",  # .. we route to these nodes\n",
    "        \"legitimate\": \"draft_response\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add the final edges\n",
    "email_graph.add_edge(\"handle_spam\", END)  # End the process after handling spam\n",
    "email_graph.add_edge(\"draft_response\", \"notify\")  # if not spam, we draft a response..\n",
    "email_graph.add_edge(\"notify\", END) # .. and notify us - END\n",
    "\n",
    "# Compile the graph\n",
    "compiled_graph = email_graph.compile()  # Compile the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize our graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/urllib3/connectionpool.py:467\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[39m\n\u001b[32m    463\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    464\u001b[39m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[32m    465\u001b[39m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[32m    466\u001b[39m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m             \u001b[43msix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:3\u001b[39m, in \u001b[36mraise_from\u001b[39m\u001b[34m(value, from_value)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/urllib3/connectionpool.py:462\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     httplib_response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    464\u001b[39m     \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[32m    465\u001b[39m     \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[32m    466\u001b[39m     \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/http/client.py:1395\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1395\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1396\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/http/client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/http/client.py:286\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/socket.py:718\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/ssl.py:1314\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1311\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1312\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1313\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/ssl.py:1166\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mTimeoutError\u001b[39m: The read operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mReadTimeoutError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/urllib3/connectionpool.py:799\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[39m\n\u001b[32m    797\u001b[39m     e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, e)\n\u001b[32m--> \u001b[39m\u001b[32m799\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/urllib3/util/retry.py:550\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    549\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43msix\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/urllib3/packages/six.py:770\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m    769\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/urllib3/connectionpool.py:715\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[39m\n\u001b[32m    714\u001b[39m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m715\u001b[39m httplib_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[32m    726\u001b[39m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[32m    728\u001b[39m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/urllib3/connectionpool.py:469\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/urllib3/connectionpool.py:358\u001b[39m, in \u001b[36mHTTPConnectionPool._raise_timeout\u001b[39m\u001b[34m(self, err, url, timeout_value)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[32m    359\u001b[39m         \u001b[38;5;28mself\u001b[39m, url, \u001b[33m\"\u001b[39m\u001b[33mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m % timeout_value\n\u001b[32m    360\u001b[39m     )\n\u001b[32m    362\u001b[39m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3. In Python 2 we have\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[38;5;66;03m# to specifically catch it and throw the timeout error\u001b[39;00m\n",
      "\u001b[31mReadTimeoutError\u001b[39m: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m Image(\u001b[43mcompiled_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMermaidDrawMethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPI\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/langchain_core/runnables/graph.py:631\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding)\u001b[39m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[32m    626\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    627\u001b[39m     curve_style=curve_style,\n\u001b[32m    628\u001b[39m     node_colors=node_colors,\n\u001b[32m    629\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    630\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/langchain_core/runnables/graph_mermaid.py:250\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding)\u001b[39m\n\u001b[32m    244\u001b[39m     img_bytes = asyncio.run(\n\u001b[32m    245\u001b[39m         _render_mermaid_using_pyppeteer(\n\u001b[32m    246\u001b[39m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[32m    247\u001b[39m         )\n\u001b[32m    248\u001b[39m     )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     img_bytes = \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_color\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    254\u001b[39m     supported_methods = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([m.value \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/langchain_core/runnables/graph_mermaid.py:368\u001b[39m, in \u001b[36m_render_mermaid_using_api\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, file_type)\u001b[39m\n\u001b[32m    362\u001b[39m         background_color = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m!\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackground_color\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    364\u001b[39m image_url = (\n\u001b[32m    365\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://mermaid.ink/img/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmermaid_syntax_encoded\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    366\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m?type=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m&bgColor=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackground_color\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    367\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m:\n\u001b[32m    370\u001b[39m     img_bytes = response.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/aiml25-ma3/lib/python3.11/site-packages/requests/adapters.py:713\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[32m--> \u001b[39m\u001b[32m713\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request=request)\n\u001b[32m    714\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[32m    715\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request=request)\n",
      "\u001b[31mReadTimeout\u001b[39m: HTTPSConnectionPool(host='mermaid.ink', port=443): Read timed out. (read timeout=10)"
     ]
    }
   ],
   "source": [
    "Image(compiled_graph.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example legitimate email\n",
    "legitimate_email = {\n",
    "    \"sender\": \"john.smith@example.com\",\n",
    "    \"subject\": \"Question about your services\",\n",
    "    \"body\": \"Dear Mr. Valentino, I was referred to you by a colleague and I'm interested in learning more about your consulting services. Could we schedule a call next week? Best regards, John Smith\"\n",
    "}\n",
    "\n",
    "# Example spam email\n",
    "spam_email = {\n",
    "    \"sender\": \"winner@lottery-intl.com\",\n",
    "    \"subject\": \"YOU HAVE WON $5,000,000!!!\",\n",
    "    \"body\": \"CONGRATULATIONS! You have been selected as the winner of our international lottery! To claim your $5,000,000 prize, please send us your bank details and a processing fee of $100.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process the legitimate email\n",
    "print(\"\\nProcessing legitimate email...\")\n",
    "legitimate_result = compiled_graph.invoke(\n",
    "    {\n",
    "        \"email\": legitimate_email, # invoke the graph with the email\n",
    "        \"verbose\": True,  # enable verbose output\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of our system is a `State` object. We can use this to check if our system is working as expected and use the data downstream in our application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'email': {'sender': 'john.smith@example.com',\n",
       "  'subject': 'Question about your services',\n",
       "  'body': \"Dear Mr. Valentino, I was referred to you by a colleague and I'm interested in learning more about your consulting services. Could we schedule a call next week? Best regards, John Smith\"},\n",
       " 'email_category': 'Relational',\n",
       " 'spam_reason': 'The email does not contain any suspicious links, requests for personal information, or promotional content. It is a direct inquiry about consulting services from a referred contact.',\n",
       " 'is_spam': False,\n",
       " 'draft': 'Dear Mr. Smith,\\n\\nThank you for reaching out and your interest in our consulting services.\\nI appreciate the opportunity to provide more information and discuss how we might be able to assist you.\\nForgive the slight delay, as I am currently away from the office and unable to schedule meetings directly.\\nI would be delighted to have a call with you next week to further explore potential collaboration.\\nPlease let me know your availability, and I will do my best to accommodate it.\\n\\nBest regards,\\n[Your Name]\\n[Your Position]\\n[Your Contact Information]',\n",
       " 'verbose': True}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legitimate_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing legitimate email...\n",
      "Mailbot is processing an email from winner@lottery-intl.com with subject: YOU HAVE WON $5,000,000!!!\n",
      "Mailbot has identified the email as spam. Reason: The email comes from an unfamiliar domain (lottery-intl.com), promises a large sum of money without any prior involvement or purchase, and asks for personal financial information (bank details) along with a processing fee. These are common characteristics of spam emails.\n",
      "The email has been moved to the spam folder.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Process the legitimate email\n",
    "print(\"\\nProcessing legitimate email...\")\n",
    "illegitimate_result = compiled_graph.invoke(\n",
    "    {\n",
    "        \"email\": spam_email, # invoke the graph with the email\n",
    "        \"verbose\": True,  # enable verbose output\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'email': {'sender': 'winner@lottery-intl.com',\n",
       "  'subject': 'YOU HAVE WON $5,000,000!!!',\n",
       "  'body': 'CONGRATULATIONS! You have been selected as the winner of our international lottery! To claim your $5,000,000 prize, please send us your bank details and a processing fee of $100.'},\n",
       " 'email_category': 'Spam',\n",
       " 'spam_reason': 'The email comes from an unfamiliar domain (lottery-intl.com), promises a large sum of money without any prior involvement or purchase, and asks for personal financial information (bank details) along with a processing fee. These are common characteristics of spam emails.',\n",
       " 'is_spam': True,\n",
       " 'verbose': True}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "illegitimate_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate our system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some evaluation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legitimate_emails = [\n",
    "    {\n",
    "        \"sender\": \"sarah.johnson@acme-corp.com\",\n",
    "        \"subject\": \"Meeting agenda for Thursday\",\n",
    "        \"body\": \"Hi team, Attached is the agenda for our quarterly review meeting on Thursday at 2 PM. Please review the attached documents before we meet. Let me know if you have any questions. Best, Sarah\",\n",
    "        \"is_spam\": False,\n",
    "        \"category\": \"Administrative\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"tech-support@cloudservices.net\",\n",
    "        \"subject\": \"Your support ticket #45928 has been resolved\",\n",
    "        \"body\": \"Dear valued customer, We're pleased to inform you that your recent support ticket regarding login issues has been resolved. If you continue to experience problems, please reply to this email with ticket #45928 in the subject line. Thank you for your patience. - Cloud Services Support Team\",\n",
    "        \"is_spam\": False,\n",
    "        \"category\": \"Transactional\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"notifications@linkedin.com\",\n",
    "        \"subject\": \"Michael Chen has endorsed you for Project Management\",\n",
    "        \"body\": \"Hi Alex, Michael Chen has endorsed you for Project Management on LinkedIn. View your profile to see your endorsements and send a thank you note to Michael.\",\n",
    "        \"is_spam\": False,\n",
    "        \"category\": \"Relational\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"reservation@grandhotel.com\",\n",
    "        \"subject\": \"Confirmation: Your stay on March 5-7, 2025\",\n",
    "        \"body\": \"Dear Ms. Williams, This email confirms your reservation at Grand Hotel for March 5-7, 2025. Check-in: 3 PM, Check-out: 11 AM. Reservation #: GH-789456. We look forward to welcoming you. For changes, please call 555-123-4567. Sincerely, Grand Hotel Reservations\",\n",
    "        \"is_spam\": False,\n",
    "        \"category\": \"Transactional\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"david.wilson@partnercompany.org\",\n",
    "        \"subject\": \"Proposal draft and timeline\",\n",
    "        \"body\": \"Hi Jessica, As discussed in our call yesterday, I've attached the draft proposal and project timeline for your review. Please let me know if you'd like any changes before we present this to the board next week. Regards, David\",\n",
    "        \"is_spam\": False,\n",
    "        \"category\": \"Relational\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"newsletter@industry-insights.com\",\n",
    "        \"subject\": \"March 2025 Newsletter: Industry Trends and Analysis\",\n",
    "        \"body\": \"Industry Insights Newsletter - March 2025 | Featured Article: The Impact of AI on Manufacturing | Upcoming Webinar: Supply Chain Optimization Strategies | Market Analysis: Q1 Reports | To unsubscribe, click here\",\n",
    "        \"is_spam\": False,\n",
    "        \"category\": \"Marketing\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"laura.santos@freelance-writer.me\",\n",
    "        \"subject\": \"Invoice #113 for content writing services\",\n",
    "        \"body\": \"Dear Mr. Reynolds, Please find attached invoice #113 for the content writing services provided in February 2025. Payment terms are net 30 days as per our agreement. Thank you for your business. Best regards, Laura Santos\",\n",
    "        \"is_spam\": False,\n",
    "        \"category\": \"Transactional\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"no-reply@amazon.com\",\n",
    "        \"subject\": \"Your Amazon order #112-7366425-8795621 has shipped\",\n",
    "        \"body\": \"Your package is on its way! Your order of 'Wireless Headphones' has shipped and is expected to arrive on Tuesday, April 2. Track your package: https://amazon.com/track/112-7366425-8795621\",\n",
    "        \"is_spam\": False,\n",
    "        \"category\": \"Transactional\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"alumni@university.edu\",\n",
    "        \"subject\": \"Annual Alumni Fundraising Event - Save the Date\",\n",
    "        \"body\": \"Dear Alumni, We're excited to announce our Annual Fundraising Gala will take place on May 15, 2025, at the University Grand Hall. This year's theme is 'Building Tomorrow's Leaders'. Early bird tickets available until April 10. More details to follow. University Alumni Association\",\n",
    "        \"is_spam\": False,\n",
    "        \"category\": \"Marketing\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"hr@currentemployer.com\",\n",
    "        \"subject\": \"Important: Benefits enrollment period ending soon\",\n",
    "        \"body\": \"Reminder: The annual benefits enrollment period ends on April 10, 2025. Please log in to the HR portal to review and confirm your selections for the upcoming fiscal year. If no changes are made, your current selections will roll over. Human Resources Department\",\n",
    "        \"is_spam\": False,\n",
    "        \"category\": \"Administrative\"\n",
    "    }\n",
    "]\n",
    "\n",
    "spam_emails = [\n",
    "    {\n",
    "        \"sender\": \"security-alert@bankofamerica-secure.info\",\n",
    "        \"subject\": \"Urgent: Your account has been limited\",\n",
    "        \"body\": \"Dear valued customer, We have detected suspicious activity on your account. Your access has been limited for security reasons. Please verify your identity by clicking this link immediately: http://secure-bankofamerica.info/verify\",\n",
    "        \"is_spam\": True,\n",
    "        \"category\": \"Spam\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"employment@career-opportunity.net\",\n",
    "        \"subject\": \"Make $5000/week working from home!\",\n",
    "        \"body\": \"AMAZING OPPORTUNITY! We're looking for serious people who want to earn $5000+ per week working just 2 hours per day from home! No experience needed! Limited positions available! Reply NOW with your name and phone number to secure your spot!\",\n",
    "        \"is_spam\": True,\n",
    "        \"category\": \"Spam\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"prince.nelson@royalfamily-intl.org\",\n",
    "        \"subject\": \"Confidential Business Proposal\",\n",
    "        \"body\": \"Dear Friend, I am Prince Nelson from the Royal Family of Wakanda. I need to transfer $25,000,000 out of my country and require your assistance. In return, you will receive 30% of the funds. Please reply with your bank details to proceed with this transaction. Regards, Prince Nelson\",\n",
    "        \"is_spam\": True,\n",
    "        \"category\": \"Spam\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"billing@netflix-accounts.com\",\n",
    "        \"subject\": \"Netflix Payment Failed - Update Information\",\n",
    "        \"body\": \"Dear Customer, Your Netflix payment method has expired. To avoid service interruption, please update your payment information immediately: http://netflix-account-verify.com/login\",\n",
    "        \"is_spam\": True,\n",
    "        \"category\": \"Spam\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"pharmacy-discounts@medstore24.biz\",\n",
    "        \"subject\": \"70% OFF Premium Medications - No Prescription Needed!\",\n",
    "        \"body\": \"HUGE PHARMACEUTICAL SALE! Get premium medications at 70% OFF regular prices! No prescription required! Overnight shipping available! Viagra, Cialis, Weight Loss Pills, Pain Relief, and more! Order now at www.medstore24.biz\",\n",
    "        \"is_spam\": True,\n",
    "        \"category\": \"Spam\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"customer-service@apple.id-verify.com\",\n",
    "        \"subject\": \"Your Apple ID was used to sign in on a new device\",\n",
    "        \"body\": \"Dear Customer, Your Apple ID was recently used to sign in on an unknown device in Kyiv, Ukraine. If this wasn't you, your account may be compromised. Secure your account now: https://apple-id-verification.com/secure\",\n",
    "        \"is_spam\": True,\n",
    "        \"category\": \"Spam\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"irs.refunds@tax-return-service.org\",\n",
    "        \"subject\": \"IRS: You have a tax refund pending\",\n",
    "        \"body\": \"ATTENTION: The Internal Revenue Service has calculated your tax return and determined you are eligible for an additional refund of $1,427.89. To claim your refund, click here to verify your identity and provide your direct deposit information: https://irs-tax-refunds.org/claim\",\n",
    "        \"is_spam\": True,\n",
    "        \"category\": \"Spam\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"james.wilson@businessproposal.co\",\n",
    "        \"subject\": \"Re: Our discussion last week\",\n",
    "        \"body\": \"Hello, Following up on our discussion last week regarding the investment opportunity. As I mentioned, this is a limited-time offer with 300% guaranteed returns within 3 months. Minimum investment is only $1000. Let me know if you're ready to proceed. James Wilson, Investment Specialist\",\n",
    "        \"is_spam\": True,\n",
    "        \"category\": \"Spam\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"track-delivery@fedex-shipping.info\",\n",
    "        \"subject\": \"FedEx: Your package delivery status\",\n",
    "        \"body\": \"Notification: We attempted to deliver your package today but were unable to due to an incorrect address. To reschedule delivery, please confirm your details here: http://fedex-delivery-reschedule.info/form. Reference: FDX-78542136\",\n",
    "        \"is_spam\": True,\n",
    "        \"category\": \"Spam\"\n",
    "    },\n",
    "    {\n",
    "        \"sender\": \"support@microsoft-security-team.net\",\n",
    "        \"subject\": \"Critical Windows Security Alert - Immediate Action Required\",\n",
    "        \"body\": \"WARNING: Your Windows computer has been infected with dangerous malware that is stealing your personal information. Our security scan detected 13 viruses on your system. Download and run our free security tool immediately to remove these threats: www.microsoft-security-scan.net/download\",\n",
    "        \"is_spam\": True,\n",
    "        \"category\": \"Spam\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:34<00:00,  4.71s/it]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_email_classifications(ground_truth, predictions):\n",
    "    \"\"\"\n",
    "    Evaluate email classification performance.\n",
    "    \n",
    "    Parameters:\n",
    "    - ground_truth: List of email dictionaries with true labels\n",
    "    - predictions: List of state dictionaries with model predictions\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    # Extract true values and predictions\n",
    "    true_spam = [email[\"is_spam\"] for email in ground_truth]\n",
    "    pred_spam = [pred[\"is_spam\"] for pred in predictions]\n",
    "    \n",
    "    # Calculate spam detection metrics\n",
    "    spam_f1 = f1_score(true_spam, pred_spam)\n",
    "    return spam_f1\n",
    "\n",
    "\n",
    "# Combine legitimate and spam emails\n",
    "ground_truth = legitimate_emails + spam_emails\n",
    "\n",
    "predictions = []\n",
    "for email in tqdm(ground_truth):\n",
    "\n",
    "    response = compiled_graph.invoke({\"email\": email, \"verbose\": False})\n",
    "    predictions.append({\"is_spam\": response[\"is_spam\"]})\n",
    "\n",
    "# Evaluate\n",
    "results = evaluate_email_classifications(ground_truth, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for spam detection: 0.82 with model 'watsonx/ibm/granite-3-2-8b-instruct'\n"
     ]
    }
   ],
   "source": [
    "print(f\"F1 Score for spam detection: {results:.2f} with model '{model.model_id}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what we might do to optimize performance? What else could we evaluate?\n",
    "\n",
    "We could \n",
    "\n",
    "| Optimization directions                     | Description                                                                 |\n",
    "|----------------------------------------------------|-----------------------------------------------------------------------------|\n",
    "| Update our system prompts                          | Refine the prompts to improve LLM understanding and output quality.        |\n",
    "| Add more nodes to our system                       | Introduce additional functionalities, such as an LLM-as-a-reviewer node.   |\n",
    "| Change the LLM                                     | Experiment with different language models to compare performance.          |\n",
    "| Change the LLM parameters                          | Adjust parameters like temperature or token limits for better results.     |\n",
    "| Add definitions for our categories                 | Provide clear definitions to improve classification accuracy.              |\n",
    "\n",
    "\n",
    "We could also evaluate our category classifier and spam classifier separately."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml25-ma3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
